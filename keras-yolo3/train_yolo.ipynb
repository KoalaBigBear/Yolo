{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"train_yolo.ipynb","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["!pip install h5py==2.10.0 --force-reinstall"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":556},"id":"PhOIU039k5HL","executionInfo":{"status":"ok","timestamp":1654970071418,"user_tz":-480,"elapsed":14006,"user":{"displayName":"Tung Nguyen","userId":"07010074400944865797"}},"outputId":"4e133fd2-9b37-420e-f5e0-4e84fbe7c087"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting h5py==2.10.0\n","  Using cached h5py-2.10.0-cp37-cp37m-manylinux1_x86_64.whl (2.9 MB)\n","Collecting six\n","  Using cached six-1.16.0-py2.py3-none-any.whl (11 kB)\n","Collecting numpy>=1.7\n","  Using cached numpy-1.21.6-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (15.7 MB)\n","Installing collected packages: six, numpy, h5py\n","  Attempting uninstall: six\n","    Found existing installation: six 1.16.0\n","    Uninstalling six-1.16.0:\n","      Successfully uninstalled six-1.16.0\n","  Attempting uninstall: numpy\n","    Found existing installation: numpy 1.21.6\n","    Uninstalling numpy-1.21.6:\n","      Successfully uninstalled numpy-1.21.6\n","  Attempting uninstall: h5py\n","    Found existing installation: h5py 2.10.0\n","    Uninstalling h5py-2.10.0:\n","      Successfully uninstalled h5py-2.10.0\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","kapre 0.3.7 requires tensorflow>=2.0.0, but you have tensorflow 1.13.1 which is incompatible.\n","google-colab 1.0.0 requires six~=1.15.0, but you have six 1.16.0 which is incompatible.\n","datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n","albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n","Successfully installed h5py-2.10.0 numpy-1.21.6 six-1.16.0\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["h5py","numpy","six"]}}},"metadata":{}}]},{"cell_type":"code","source":["!pip install tensorflow==1.13.1\n","!pip install keras==2.2.4\n"],"metadata":{"id":"bXDe9-qiazrr","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1654970097416,"user_tz":-480,"elapsed":9497,"user":{"displayName":"Tung Nguyen","userId":"07010074400944865797"}},"outputId":"e7d5f30e-b770-4e88-dd5a-6d93aabb1ea1"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: tensorflow==1.13.1 in /usr/local/lib/python3.7/dist-packages (1.13.1)\n","Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (1.16.0)\n","Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (3.17.3)\n","Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (1.46.3)\n","Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (1.21.6)\n","Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (0.8.1)\n","Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (1.1.2)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (1.1.0)\n","Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (1.0.8)\n","Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (0.5.3)\n","Requirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (1.0.0)\n","Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (0.37.1)\n","Requirement already satisfied: tensorflow-estimator<1.14.0rc0,>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (1.13.0)\n","Requirement already satisfied: tensorboard<1.14.0,>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (1.13.1)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.6->tensorflow==1.13.1) (2.10.0)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.1) (1.0.1)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.1) (3.3.7)\n","Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.1) (4.11.4)\n","Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.1) (4.2.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.1) (3.8.0)\n","Requirement already satisfied: mock>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-estimator<1.14.0rc0,>=1.13.0->tensorflow==1.13.1) (4.0.3)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: keras==2.2.4 in /usr/local/lib/python3.7/dist-packages (2.2.4)\n","Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from keras==2.2.4) (1.16.0)\n","Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from keras==2.2.4) (1.1.2)\n","Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.7/dist-packages (from keras==2.2.4) (1.4.1)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from keras==2.2.4) (3.13)\n","Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.7/dist-packages (from keras==2.2.4) (1.0.8)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras==2.2.4) (2.10.0)\n","Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from keras==2.2.4) (1.21.6)\n"]}]},{"cell_type":"code","source":["!pip install tensorflow-gpu==1.13.1"],"metadata":{"id":"Ok5GOK2es4i6","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1654970102001,"user_tz":-480,"elapsed":2854,"user":{"displayName":"Tung Nguyen","userId":"07010074400944865797"}},"outputId":"e5791390-7450-4b2a-abb9-34f7e2ce47fe"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: tensorflow-gpu==1.13.1 in /usr/local/lib/python3.7/dist-packages (1.13.1)\n","Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.13.1) (1.0.8)\n","Requirement already satisfied: tensorflow-estimator<1.14.0rc0,>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.13.1) (1.13.0)\n","Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.13.1) (0.5.3)\n","Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.13.1) (3.17.3)\n","Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.13.1) (0.37.1)\n","Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.13.1) (1.1.2)\n","Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.13.1) (1.21.6)\n","Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.13.1) (1.16.0)\n","Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.13.1) (1.46.3)\n","Requirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.13.1) (1.0.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.13.1) (1.1.0)\n","Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.13.1) (0.8.1)\n","Requirement already satisfied: tensorboard<1.14.0,>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.13.1) (1.13.1)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.6->tensorflow-gpu==1.13.1) (2.10.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow-gpu==1.13.1) (3.3.7)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow-gpu==1.13.1) (1.0.1)\n","Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.14.0,>=1.13.0->tensorflow-gpu==1.13.1) (4.11.4)\n","Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.14.0,>=1.13.0->tensorflow-gpu==1.13.1) (4.2.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.14.0,>=1.13.0->tensorflow-gpu==1.13.1) (3.8.0)\n","Requirement already satisfied: mock>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-estimator<1.14.0rc0,>=1.13.0->tensorflow-gpu==1.13.1) (4.0.3)\n"]}]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yUu6AmPqcOUi","executionInfo":{"status":"ok","timestamp":1654970111034,"user_tz":-480,"elapsed":2271,"user":{"displayName":"Tung Nguyen","userId":"07010074400944865797"}},"outputId":"6b828175-ad81-4367-8796-3cdd89ed2512"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["import os"],"metadata":{"id":"7eShLbZtiY_w","executionInfo":{"status":"ok","timestamp":1654970113530,"user_tz":-480,"elapsed":259,"user":{"displayName":"Tung Nguyen","userId":"07010074400944865797"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["os.chdir('/content/drive/MyDrive/ColabNotebooks/Yolo/keras-yolo3/')\n","os.getcwd()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"Ij8ImBTihMU3","executionInfo":{"status":"ok","timestamp":1654970115375,"user_tz":-480,"elapsed":287,"user":{"displayName":"Tung Nguyen","userId":"07010074400944865797"}},"outputId":"f2babd2a-cd09-4bb3-9bc6-7ecde3af3c24"},"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'/content/drive/MyDrive/ColabNotebooks/Yolo/keras-yolo3'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":5}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tU578ZHwaiP5","outputId":"8b0ff8d8-9a90-4d0f-ab7f-aecb74e8b1a7"},"outputs":[{"output_type":"stream","name":"stderr","text":["Using TensorFlow backend.\n","/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n","/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n","/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n","/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n","/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n","/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"]}],"source":["import numpy as np\n","import keras.backend as K\n","from keras.layers import Input, Lambda\n","from keras.models import Model\n","from keras.optimizers import Adam\n","from keras.callbacks import TensorBoard, ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n","\n","from yolo3.model import preprocess_true_boxes, yolo_body, tiny_yolo_body, yolo_loss\n","from yolo3.utils import get_random_data\n"]},{"cell_type":"code","source":["os.chdir('/content/drive/MyDrive/ColabNotebooks/Yolo/keras-yolo3/')\n","os.getcwd()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"SQgb3y1_ipkN","executionInfo":{"status":"ok","timestamp":1654948964597,"user_tz":-480,"elapsed":277,"user":{"displayName":"Tung Nguyen","userId":"07010074400944865797"}},"outputId":"a8b2e2d1-81c7-40f4-b6c6-b091fc307164"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'/content/drive/MyDrive/ColabNotebooks/Yolo/keras-yolo3'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":["def _main():\n","    annotation_path = 'model_data/CLASS_test.txt'\n","    log_dir = 'logs/000/'\n","    classes_path = 'model_data/CLASS_test_classes.txt'\n","    anchors_path = 'model_data/yolo_anchors.txt'\n","    class_names = get_classes(classes_path)\n","    num_classes = len(class_names)\n","    anchors = get_anchors(anchors_path)\n","\n","    input_shape = (416,416) # multiple of 32, hw\n","\n","    is_tiny_version = len(anchors)==6 # default setting\n","    if is_tiny_version:\n","        model = create_tiny_model(input_shape, anchors, num_classes,\n","            freeze_body=2, weights_path='model_data/tiny_yolo_weights.h5')\n","    else:\n","        model = create_model(input_shape, anchors, num_classes,\n","            freeze_body=2, weights_path='model_data/yolo_weights.h5') # make sure you know what you freeze\n","\n","    logging = TensorBoard(log_dir=log_dir)\n","    checkpoint = ModelCheckpoint(log_dir + 'ep{epoch:03d}-loss{loss:.3f}-val_loss{val_loss:.3f}.h5',\n","        monitor='val_loss', save_weights_only=True, save_best_only=True, period=3)\n","    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3, verbose=1)\n","    early_stopping = EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=1)\n","\n","    val_split = 0.1\n","    with open(annotation_path) as f:\n","        lines = f.readlines()\n","    np.random.seed(10101)\n","    np.random.shuffle(lines)\n","    np.random.seed(None)\n","    num_val = int(len(lines)*val_split)\n","    num_train = len(lines) - num_val\n","\n","    # Train with frozen layers first, to get a stable loss.\n","    # Adjust num epochs to your dataset. This step is enough to obtain a not bad model.\n","    if True:\n","        model.compile(optimizer=Adam(lr=1e-3), loss={\n","            # use custom yolo_loss Lambda layer.\n","            'yolo_loss': lambda y_true, y_pred: y_pred})\n","\n","        batch_size = 32\n","        print('Train on {} samples, val on {} samples, with batch size {}.'.format(num_train, num_val, batch_size))\n","        model.fit_generator(data_generator_wrapper(lines[:num_train], batch_size, input_shape, anchors, num_classes),\n","                steps_per_epoch=max(1, num_train//batch_size),\n","                validation_data=data_generator_wrapper(lines[num_train:], batch_size, input_shape, anchors, num_classes),\n","                validation_steps=max(1, num_val//batch_size),\n","                epochs=50,\n","                initial_epoch=0,\n","                callbacks=[logging, checkpoint])\n","        model.save_weights(log_dir + 'trained_weights_stage_1.h5')\n","\n","    # Unfreeze and continue training, to fine-tune.\n","    # Train longer if the result is not good.\n","    if True:\n","        for i in range(len(model.layers)):\n","            model.layers[i].trainable = True\n","        model.compile(optimizer=Adam(lr=1e-4), loss={'yolo_loss': lambda y_true, y_pred: y_pred}) # recompile to apply the change\n","        print('Unfreeze all of the layers.')\n","\n","        batch_size = 8 # note that more GPU memory is required after unfreezing the body\n","        print('Train on {} samples, val on {} samples, with batch size {}.'.format(num_train, num_val, batch_size))\n","        model.fit_generator(data_generator_wrapper(lines[:num_train], batch_size, input_shape, anchors, num_classes),\n","            steps_per_epoch=max(1, num_train//batch_size),\n","            validation_data=data_generator_wrapper(lines[num_train:], batch_size, input_shape, anchors, num_classes),\n","            validation_steps=max(1, num_val//batch_size),\n","            epochs=100,\n","            initial_epoch=50,\n","            callbacks=[logging, checkpoint, reduce_lr, early_stopping])\n","        model.save_weights(log_dir + 'trained_weights_final.h5')\n","\n","    # Further training if needed."],"metadata":{"id":"9kAmyA_Ziexs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def get_classes(classes_path):\n","    '''loads the classes'''\n","    with open(classes_path) as f:\n","        class_names = f.readlines()\n","    class_names = [c.strip() for c in class_names]\n","    return class_names\n","\n","def get_anchors(anchors_path):\n","    '''loads the anchors from a file'''\n","    with open(anchors_path) as f:\n","        anchors = f.readline()\n","    anchors = [float(x) for x in anchors.split(',')]\n","    return np.array(anchors).reshape(-1, 2)\n","\n","\n","def create_model(input_shape, anchors, num_classes, load_pretrained=True, freeze_body=2,\n","            weights_path='model_data/yolo_weights.h5'):\n","    '''create the training model'''\n","    K.clear_session() # get a new session\n","    image_input = Input(shape=(None, None, 3))\n","    h, w = input_shape\n","    num_anchors = len(anchors)\n","\n","    y_true = [Input(shape=(h//{0:32, 1:16, 2:8}[l], w//{0:32, 1:16, 2:8}[l], \\\n","        num_anchors//3, num_classes+5)) for l in range(3)]\n","\n","    model_body = yolo_body(image_input, num_anchors//3, num_classes)\n","    print('Create YOLOv3 model with {} anchors and {} classes.'.format(num_anchors, num_classes))\n","\n","    if load_pretrained:\n","        model_body.load_weights(weights_path, by_name=True, skip_mismatch=True)\n","        print('Load weights {}.'.format(weights_path))\n","        if freeze_body in [1, 2]:\n","            # Freeze darknet53 body or freeze all but 3 output layers.\n","            num = (185, len(model_body.layers)-3)[freeze_body-1]\n","            for i in range(num): model_body.layers[i].trainable = False\n","            print('Freeze the first {} layers of total {} layers.'.format(num, len(model_body.layers)))\n","\n","    model_loss = Lambda(yolo_loss, output_shape=(1,), name='yolo_loss',\n","        arguments={'anchors': anchors, 'num_classes': num_classes, 'ignore_thresh': 0.5})(\n","        [*model_body.output, *y_true])\n","    model = Model([model_body.input, *y_true], model_loss)\n","\n","    return model\n","\n","def create_tiny_model(input_shape, anchors, num_classes, load_pretrained=True, freeze_body=2,\n","            weights_path='model_data/tiny_yolo_weights.h5'):\n","    '''create the training model, for Tiny YOLOv3'''\n","    K.clear_session() # get a new session\n","    image_input = Input(shape=(None, None, 3))\n","    h, w = input_shape\n","    num_anchors = len(anchors)\n","\n","    y_true = [Input(shape=(h//{0:32, 1:16}[l], w//{0:32, 1:16}[l], \\\n","        num_anchors//2, num_classes+5)) for l in range(2)]\n","\n","    model_body = tiny_yolo_body(image_input, num_anchors//2, num_classes)\n","    print('Create Tiny YOLOv3 model with {} anchors and {} classes.'.format(num_anchors, num_classes))\n","\n","    if load_pretrained:\n","        model_body.load_weights(weights_path, by_name=True, skip_mismatch=True)\n","        print('Load weights {}.'.format(weights_path))\n","        if freeze_body in [1, 2]:\n","            # Freeze the darknet body or freeze all but 2 output layers.\n","            num = (20, len(model_body.layers)-2)[freeze_body-1]\n","            for i in range(num): model_body.layers[i].trainable = False\n","            print('Freeze the first {} layers of total {} layers.'.format(num, len(model_body.layers)))\n","\n","    model_loss = Lambda(yolo_loss, output_shape=(1,), name='yolo_loss',\n","        arguments={'anchors': anchors, 'num_classes': num_classes, 'ignore_thresh': 0.7})(\n","        [*model_body.output, *y_true])\n","    model = Model([model_body.input, *y_true], model_loss)\n","\n","    return model\n","\n","def data_generator(annotation_lines, batch_size, input_shape, anchors, num_classes):\n","    '''data generator for fit_generator'''\n","    n = len(annotation_lines)\n","    i = 0\n","    while True:\n","        image_data = []\n","        box_data = []\n","        for b in range(batch_size):\n","            if i==0:\n","                np.random.shuffle(annotation_lines)\n","            image, box = get_random_data(annotation_lines[i], input_shape, random=True)\n","            image_data.append(image)\n","            box_data.append(box)\n","            i = (i+1) % n\n","        image_data = np.array(image_data)\n","        box_data = np.array(box_data)\n","        y_true = preprocess_true_boxes(box_data, input_shape, anchors, num_classes)\n","        yield [image_data, *y_true], np.zeros(batch_size)\n","\n","def data_generator_wrapper(annotation_lines, batch_size, input_shape, anchors, num_classes):\n","    n = len(annotation_lines)\n","    if n==0 or batch_size<=0: return None\n","    return data_generator(annotation_lines, batch_size, input_shape, anchors, num_classes)"],"metadata":{"id":"9MgUAQhrjtfc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""],"metadata":{"id":"xq7UyxMEr36M"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from tensorflow.python.client import device_lib\n","for dev in device_lib.list_local_devices():\n","    if dev.__getattribute__('device_type') == 'GPU':\n","        print(dev.__getattribute__('device_type'),dev.__getattribute__('physical_device_desc'))"],"metadata":{"id":"dwbwbpNusqQl","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1654948982242,"user_tz":-480,"elapsed":551,"user":{"displayName":"Tung Nguyen","userId":"07010074400944865797"}},"outputId":"86982520-51cd-44d8-f159-d85a8f99d6dc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["GPU device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n"]}]},{"cell_type":"code","source":["_main()"],"metadata":{"id":"jahcZ9d3kVRd","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1654969828978,"user_tz":-480,"elapsed":632965,"user":{"displayName":"Tung Nguyen","userId":"07010074400944865797"}},"outputId":"30ab6ebf-7feb-4e19-b7ac-fd74de0b2cfd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["337/337 [==============================] - 324s 962ms/step - loss: 26.0985 - val_loss: 29.2745\n","\n","Epoch 00072: ReduceLROnPlateau reducing learning rate to 9.999999939225292e-10.\n","Epoch 73/100\n","337/337 [==============================] - 322s 957ms/step - loss: 26.2780 - val_loss: 30.8871\n","Epoch 00073: early stopping\n"]}]}]}